\section{Theory}

\section{Theory}

\subsection{Variational Monte Carlo}

Monte Carlo simulations are widely used methods in numerical science that employs random walkers. 
In this project we are taking a closer look at trapped bosons. We are given a trail wave function we assume is as close to the real case as possible, $\Psi_T(\mathbf{R};\alpha)$ where $\mathbf{R} = (\mathbf{R}_1, ... , \mathbf{R}_N)$ is the position of the different particles. 
From quantum mechanics we know the probability distribution is given by the wave function. 

$$P(\mathbf{R}; \alpha) = \frac{|\Psi_T(\mathbf{R};\alpha)|^2}{\int |\Psi_T(\mathbf{R};\alpha)|^2 d\mathbf{R}}$$

Monte Carlo integration allow us to evaluate the integral at hand. The expectation value of the Hamiltonian is given as follows. 

$$\langle \widehat{\mathbf{H}}\rangle = \frac{\int d \mathbf{R} \Psi^{\ast} (\mathbf{R})H(\mathbf{R}) \Psi(\mathbf{R})}{\int d \mathbf{R} \Psi^{\ast} (\mathbf{R}) \Psi(\mathbf{R})}$$

The variational principle states that the expectation value of the Hamiltonian is an upper-bound for the ground state energy of the Hamiltonian.

$$E_0 \leq \langle H \rangle$$

This is what the Variational Monte Carlo method bases itself on. Given a probability distribution we can evaluate the wave function and look for a local minimum. We define the local energy by

$$\widehat{\mathbf{E}}_L(\mathbf{R};\alpha) = \frac{1}{\Psi_T(\mathbf{R};\alpha)}\widehat{\mathbf{H}}\Psi_T(\mathbf{R};\alpha).$$

Then the expectation value of the local energy is given by

$$\langle \widehat{\mathbf{E}}_L\rangle = \int P(\mathbf{R}) \widehat{\mathbf{E}}_L d\mathbf{R} \approx \frac{1}{N} \sum_{i = 1}^N \mathbf{E_L}(x_i)$$

where $N$ is the number of Monte Carlo cycles. Now we can calculate the probability distribution and the local energy. And for each cycle we propose a new configuration $\mathbf{R}_p$ for the system and hopefully we come closer to the ground state.

$$\mathbf{R}_p = \mathbf{R} + r \ast \Delta \mathbf{R}$$

\subsection{The Metropolis Algorithm}

How we select the new configurations during the simulation is given by the Metropolis Algorithm.

$P_i^{(n)} \rightarrow$ probability of finding the system in state $i$ at the n'th step.
\\
$j \rightarrow$ possible new step with probability $T_{i \rightarrow j}$
\\
$A_{i \rightarrow j} \rightarrow$ probability of acceptance. 
\\
We want to try and push the system towards a 
Generate a new possible state with transition possibility 
$T_{j \rightarrow i}$ 

$1 - A_{i \rightarrow j} \rightarrow$ rejection

$$P_i^{(n \rightarrow \infty)} \rightarrow p_i$$

$$P_i^{(n)} = \sum_j \left[P_j^{(n-1)} T_{j \rightarrow i}A_{j \rightarrow i} + P_j^{(n-1)}T_{i \rightarrow j}(1 - A_{i \rightarrow j})\right]$$

$$\sum_j [p_j T_{j \rightarrow i}A_{j \rightarrow i} - p_i T_{i \rightarrow j}A_{i \rightarrow j}] = 0$$

$$\frac{A_{j \rightarrow i}}{A_{i \rightarrow j}} = \frac{p_i T_{i \rightarrow j}}{p_j T_{j \rightarrow i}}$$

$$A_{j \rightarrow i} = \mathrm{min} \left( 1, \frac{p_i T_{i \rightarrow j}}{p_j T_{j \rightarrow i}}\right)$$

\subsection{Numerical differentiation}
To evaluate the local energy of the system as defined in the project it necessary to compute the second derivative of the trial wavefunction $\psi_T$. We've chosen to implement the numerical differentiation as a finite difference approximation. Let $\mathbf{R}$ be the row major $N \times D$ matrix where $N$ is the number of particles and $D$ is their dimension. Then the second derivative can be found by the procedure listed as algorithm \ref{alg:nd}


Since the derivative involves three function calls for each particle the numerical derivative will obviously be quite computationally expensive. It is noted  that the differentiation could be substantially optimized from the version included in the code, but is outside the scope of this project. 

\begin{algorithm}[H]
\KwData{matrix $\mathbf{R}$}
\KwResult{float $\nabla ^2 \psi_T (R)$}
\BlankLine
$\Delta = 0$ \\
$\mathbf{R_p} = \mathbf{R}$\\
$\mathbf{R_m} = \mathbf{R}$\\
\BlankLine
\For{$i$ in $[0, N-1]$}{
	\For{$j$ in $[0, D-1]$}{
		$\mathbf{R_p}(i,j) += h$ \\
		$\mathbf{R_m}(i,j) -= h$ \\
		$\Delta = \psi_T(\mathbf{R_p}) + \psi_T(\mathbf{R_m}) - 2 \psi_T(\mathbf{R})$\\

		$\mathbf{R_p}(i,j) -= h$ \\
		$\mathbf{R_m}(i,j) += h$ \\
	}
}
\KwRet{$\frac{\Delta}{h^2} $}
\BlankLine
\caption{Numerical differentiation of the second order of the trial wavefunction on a system $\mathbf{R}$}\label{alg:nd}
\end{algorithm} 


\subsection{Importance Sampling}

\subsection{Gradient Descent}
Like most problems in physics the variational quantum problem is one of optimization. In this project we are optimizing the expectation value of the energy over the parameter $\alpha$. In the naive implementation we simply span a reasonable range of $\alpha$ \footnote{an implementation of which can be seen in the file \lstinline{main_b.cpp}}. For a multi-parameter variational problem this approach is too computationally expensive to implement in most cases. To remedy this problem iterative gradient methods have been developed to make more intelligent choices for the variational parameters. In this project we have opted to implement a simple gradient descent method. The gradient descent is ordinarily presented as 

\begin{equation}
\alpha_{i+1} = \alpha_i -\gamma \frac{\partial \langle E_L^i \rangle}{\partial \alpha}
\end{equation}

\noindent Where we have opted to update the parameter $\gamma$ iteratively by the Barzilai-Borwein formula 

\begin{equation}
\gamma_i = \left |(\alpha_{i+1} - \alpha) \cdot \frac{1}{\expect{E_L}^{i+1} - \expect{E_L}^i}\right|
\end{equation}

\noindent We also introduce the notation $\frac{\partial \langle E_L^i \rangle}{\partial \alpha} = \expect{E_L}^\alpha_{i}$ for brevity, and the same notation will be used for the tiral wavefunction $\psi_T$. The partial derivative itself can be found by the equation\footnote{The equation was retrieved from the lecture notes} 

\begin{equation}
\expect{E_l}^\alpha_{i} = 2 \left(\expect{\frac{\psi^\alpha}{\psi} E_L}^i - \expect{\frac{\psi^\alpha}{\psi}}\expect{E_L}^i \right)
\end{equation} 

\noindent Wherein the fraction of the partial derivative of the wavefunction by the wavefunction must be derived, which is trivial with the ansatz of the wavefunction. 


\begin{align}
\frac{\psi^\alpha}{\psi} &= \frac{\psi \prod_i^N (x_i^2 + y_i^2 + \beta z^2_i)}{\psi} \\
&= \prod_i^N (x_i^2 + y_i^2 + \beta z^2_i)
\end{align}
\noindent This holds for both the interactive and non-interactive case since the correlation wavefunction, $f(r_i, r_j)$, does not have any dependence on $\alpha$

\subsection{Blocking Method}

