\section{Local energy with $\psi(x) = F_{rbm}$}

Given the Hamiltonian in eq. \ref{eq:Hamilt} the expression for the local energy is given by the following.

\begin{align*}
E_L &= \frac{1}{\Psi}\hat{H}\psi \\
&= \sum_{k}^{P} \frac{1}{2} \left( -\frac{1}{\Psi} \nabla_k^2 \Psi +  \omega^2 r_k^2 \right) + \sum_{k < l} \frac{1}{r_{kl}}
\end{align*}

We wish to find the Laplacian of the NQS wave function. Since our visible nodes represents the particle positions in Cartesian coordinates the Laplace operator takes the second partial derivative with respect to each independent variable in the vector space. It can therefore be written as  

\begin{equation*}
\nabla_k^2 \Psi = \sum_{l}^{D} \frac{\partial^2}{\partial x_{kl}^2} \Psi.
\end{equation*}

\begin{equation*}
E_L = \sum_{k}^{P} \sum_{l}^{D} \frac{1}{2} \left( -\frac{1}{\Psi} \frac{\partial^2}{\partial x_{kl}^2} \Psi +  \omega^2 r_k^2 \right) + \sum_{k < l} \frac{1}{r_{kl}}
\end{equation*}

\begin{equation*}
E_L = \sum_{i}^{M} \frac{1}{2} \left( -\frac{1}{\Psi} \frac{\partial^2}{\partial X_{i}^2} \Psi +  \omega^2 X_i^2 \right) +  \sum_{k < l} \frac{1}{r_{kl}}
\end{equation*}

In the above equation we have used the fact that the number of visible nodes are $M = P \cdot D$. This reduces the number of sums in the first term to one. Also we see that it would be an advantage to solve the derivatives of $\ln \Psi$ since our wave function consist of sums in the exponential and also removes the $\Psi$ in the denominator. Thus the identity below is helpful. 

\begin{equation*}
\frac{1}{\Psi} \frac{\partial^2}{\partial X_{i}^2} \Psi = \left( \frac{\partial}{\partial X_{i}} \ln \Psi \right)^2 + \frac{\partial^2}{\partial X_{i}^2} \ln \Psi
\end{equation*}


\begin{equation*}
E_L = \sum_{i}^{M} \frac{1}{2} \left( - \left( \frac{\partial}{\partial X_{i}} \ln \Psi \right)^2 + \frac{\partial^2}{\partial X_{i}^2} \ln \Psi  + \omega^2 X_i^2 \right) +  \sum_{k < l} \frac{1}{r_{kl}}
\end{equation*}

Our local energy can be rewritten and we must now solve both the first and second derivative of the wave function. Our wave function is represented by the marginal probability $F_{rbm}$.

\begin{align*}
\Psi(X) &= F_{rbm}(X) \\
&= \frac{1}{Z} \exp \left( -\sum_{i}^{M} \frac{(X_i - a_i)^2}{2 \sigma^2} \right) \prod_{j}^{N} \left( 1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \right)
\end{align*}


\begin{equation*}
\ln \Psi = -\ln Z - \sum_{i}^{M} \frac{(X_i - a_i)^2}{2 \sigma^2} +  \sum_{j}^{N} \ln \left(1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \right)
\end{equation*}

Since $Z$ is the normalization constant its derivative is zero and can be removed.
We end up with the following

\begin{align*}
\nabla_i \ln \Psi &= \nabla_i \left( - \sum_{i}^{M} \frac{(X_i - a_i)^2}{2 \sigma^2} +  \sum_{j}^{N} \ln \left( 1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \right) \right) \\
&= \frac{\partial}{\partial X_i} \left( - \sum_{i}^{M} \frac{(X_i - a_i)^2}{2 \sigma^2} +  \sum_{j}^{N} \ln \left(1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \right) \right)\\
&= \frac{-2 (X_i - a_i) 2 \sigma^2}{(2 \sigma^2)^2} + \sum_{j}^{N} \frac{1}{1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right)} \left( \frac{\omega_{ij}}{\sigma^2} \right) \exp \left(  b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \\
&= \frac{-(X_i - a_i)}{\sigma^2} + \frac{1}{\sigma^2}\sum_{j}^{N} \frac{\omega_{ij}}{1 + \exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right)}
\end{align*}

Given the first derivative we now find the second derivative. And we have solved the analytic case of the local energy.

\begin{align*}
\nabla_i^2 \ln \Psi &= \nabla_i^2 \left( - \sum_{i}^{M} \frac{(X_i - a_i)^2}{2 \sigma^2} +  \sum_{j}^{N} \ln \left( 1 + \exp \left( b_j + \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \right) \right) \\
&= \frac{\partial}{\partial X_i} \left( \frac{-(X_i - a_i)}{\sigma^2} + \frac{1}{\sigma^2} \sum_{j}^{N} \frac{\omega_{ij}}{1 + \exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right)} \right) \\
&= -\frac{1}{\sigma^2} + \frac{1}{\sigma^2} \sum_{j}^{N} \frac{-\omega_{ij}}{\left(1 + \exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right)\right)^2} \left( \frac{-\omega_{ij}}{\sigma^2} \right) \exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) \\
&= -\frac{1}{\sigma^2} + \frac{1}{\sigma^4} \sum_{j}^{N} \frac{\left(\omega_{ij}\right)^2  }{\left(1 + \exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right)\right)^2}\exp \left( -b_j - \sum_{i}^{M} \frac{X_i \omega_{ij}}{\sigma^2} \right) 
\end{align*}

\section{Gradients with respect to RMB parameters, $\psi(x) = F_{rbm}$}\label{sec:GD}

To find the local energy minimum of the NQS wavefunction the  gradient of the local energy with respect to the variational parameter $\alpha  = \{\mathbf{a}, \mathbf{b}, \mathbf{W} \}$ needs to be computed. For each variational parameter $\alpha_i \in \alpha$ the gradient is defined as in equation \ref{eq:var_grad} 

\begin{equation}\label{eq:var_grad}
G_i = \frac{\partial \expect{E_L}}{\partial \alpha_i} = 2\left( \expect{E_L \frac{1}{\Psi} \frac{\partial \Psi}{\partial \alpha_i}}  - \expect{E_L} \expect{ \frac{1}{\Psi} \frac{\partial \Psi}{\partial \alpha_i}}\right)    
\end{equation}

\noindent While the NQS is defined for the Gaussian Binary RBM as (REPLACE WITH REF TO EQ )

\begin{align*}
\Psi (\mathbf{X}) = \frac{1}{Z} \exp\left(-\sum_i^M \frac{(X_i - a_i)^2}{2\sigma^2}\right) 
    \prod_j ^N \left( 1 + \exp\left(b_j  + \sum_i^M \frac{X_i w^\mathbf{T}_{ij}}{\sigma^2}\right) \right)
\end{align*}
    
\noindent We now find it useful to use the identity 
\begin{align}
    \frac{d}{dx}\ln f(x) = \frac{1}{f(x)} \frac{d}{dx}f(x)
\end{align}

\noindent Taking the logarithm of the NQS wavefunction then gives

\begin{align}
    \ln( \Psi(\mathbf{X}) )  = \ln{\frac{1}{Z}} -\sum_i^M \frac{(X_i - a_i)^2}{2\sigma^2} 
    + \sum_j^N \ln\left[  1 + \exp\left(b_j  + \sum_i^M \frac{X_i w^\mathbf{T}_{ij}}{\sigma^2}\right) \right]
\end{align}

\noindent  The final result for the gradient of the components of $\alpha_i$ is then  

\begin{align}
    \frac{\partial \ln( \Psi(\mathbf{X}) )}{\partial a_k} &= \frac{1}{\sigma ^2} (X_k - a_k)\\
    \frac{\partial \ln( \Psi(\mathbf{X}) )}{\partial b_n} &= \left(1 +  \exp\left(- b_n  - \sum_i^M \frac{X_i w^\mathbf{T}_{in}}{\sigma^2}\right)  \right)^{-1}  \\
    \frac{\partial \ln( \Psi(\mathbf{X}) )}{\partial w_{kn}}& = \frac{X_k}{\sigma^2} \left(1 +  \exp\left(- b_n  - \sum_i^M \frac{X_i w^\mathbf{T}_{in}}{\sigma^2}\right)  \right)^{-1}   
\end{align}
